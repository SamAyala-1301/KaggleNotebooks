{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"1. Dataset Class (CustomMNISTDataset)\n\t•\tReasoning:\n\t•\tWe need to create a custom dataset class to load the MNIST data from a CSV file. MNIST is typically a collection of image files, but in this case, the data is stored in a CSV format where each row represents an image (flattened pixels) and its label.\n\t•\tThe dataset must handle both training and test data (test data does not have labels, so we need to account for that).\n\t•\tImprovements:\n\t•\tYou could add more sophisticated data augmentation techniques to improve the model’s robustness, such as random rotations, flips, etc.\n\n2. Data Transforms (data_transforms)\n\t•\tReasoning:\n\t•\tThe ToTensor() transform converts image data into a PyTorch tensor, which is required for input to the neural network.\n\t•\tThe Normalize() transform standardizes the input data to have a mean of 0.5 and a standard deviation of 0.5, which is common for MNIST to make training more stable.\n\t•\tImprovements:\n\t•\tIf you’re working with a more complex dataset, you could also include other augmentations such as random cropping, flipping, etc., to artificially increase the diversity of the dataset.\n\n3. DataLoader\n\t•\tReasoning:\n\t•\tThe DataLoader efficiently loads the dataset in batches, making training and inference faster by utilizing multiple worker threads for data loading.\n\t•\tThe shuffle=False is used for the test set since we don’t need to shuffle the data when making predictions.\n\t•\tImprovements:\n\t•\tFor validation data, you may want to use shuffle=True during training to prevent the model from overfitting on the sequential order of data.\n\n4. Model Architecture (SimpleCNN)\n\t•\tReasoning:\n\t•\tThe model uses Convolutional Neural Networks (CNNs) because CNNs are highly effective for image classification tasks.\n\t•\tThe model starts with 3 convolutional layers followed by ReLU activations and max pooling, which reduces spatial dimensions and extracts important features.\n\t•\tFinally, fully connected layers are used to classify the image into one of the 10 categories (digits 0-9).\n\t•\tImprovements:\n\t•\tAdding more layers or experimenting with different architectures like ResNet or VGG could improve performance if needed.\n\n5. Device Setup (GPU/CPU)\n\t•\tReasoning:\n\t•\tThe code automatically selects a GPU if one is available. Using a GPU speeds up training and inference, especially for deep neural networks.\n\t•\tImprovements:\n\t•\tIf you’re working in a multi-GPU environment, you could use DataParallel or DistributedDataParallel for scaling.\n\n6. Model Inference\n\t•\tReasoning:\n\t•\tDuring evaluation (model.eval()), dropout and batch normalization are disabled, ensuring the model’s performance is not affected by randomness.\n\t•\tThe model makes predictions using the test data, and the results are stored in the predictions list.\n\t•\tImprovements:\n\t•\tFor further optimization, you could perform inference using batching on a GPU, which will speed up the process.\n\n7. Submission Preparation\n\t•\tReasoning:\n\t•\tThe predictions are converted into a DataFrame to create the required format for Kaggle submissions.\n\t•\tImprovements:\n\t•\tYou could add more metadata to the submission, such as confidence scores for each prediction.\n\n8. Saving Predictions\n\t•\tReasoning:\n\t•\tThe predictions are saved as a CSV file using to_csv(), which is the format required for Kaggle submissions.","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T07:10:29.205928Z","iopub.execute_input":"2024-12-31T07:10:29.206323Z","iopub.status.idle":"2024-12-31T07:10:29.210808Z","shell.execute_reply.started":"2024-12-31T07:10:29.206296Z","shell.execute_reply":"2024-12-31T07:10:29.209680Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"# Define CustomMNISTDataset\nclass CustomMNISTDataset(Dataset):\n    def __init__(self, csv_file, transform=None, is_test=False):\n        self.data_frame = pd.read_csv(csv_file)\n        self.transform = transform\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.data_frame)\n\n    def __getitem__(self, index):\n        item = self.data_frame.iloc[index]\n        if self.is_test:\n            image = item.values.reshape(28, 28).astype(np.uint8)\n            label = None\n        else:\n            image = item[1:].values.reshape(28, 28).astype(np.uint8)\n            label = item.iloc[0]\n\n        image = transforms.ToPILImage()(image)\n        if self.transform is not None:\n            image = self.transform(image)\n        if self.is_test:\n            return image  # Only the image for test set\n        else:\n            return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T07:10:29.212064Z","iopub.execute_input":"2024-12-31T07:10:29.212422Z","iopub.status.idle":"2024-12-31T07:10:29.224400Z","shell.execute_reply.started":"2024-12-31T07:10:29.212384Z","shell.execute_reply":"2024-12-31T07:10:29.223661Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"# Define transformations\ndata_transforms = transforms.Compose([\n    transforms.ToTensor(),  # Convert image to PyTorch tensor (C, H, W)\n    transforms.Normalize((0.5,), (0.5,))  # Normalize pixel values to [-1, 1]\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T07:10:29.225814Z","iopub.execute_input":"2024-12-31T07:10:29.226053Z","iopub.status.idle":"2024-12-31T07:10:29.237662Z","shell.execute_reply.started":"2024-12-31T07:10:29.226031Z","shell.execute_reply":"2024-12-31T07:10:29.236990Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"# Create dataset and DataLoader\ntrain_dataset = CustomMNISTDataset(\"/kaggle/input/digit-recognizer/train.csv\", transform=data_transforms, is_test=False)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T07:10:29.238878Z","iopub.execute_input":"2024-12-31T07:10:29.239120Z","iopub.status.idle":"2024-12-31T07:10:30.907112Z","shell.execute_reply.started":"2024-12-31T07:10:29.239101Z","shell.execute_reply":"2024-12-31T07:10:30.906385Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"# Visualize a single batch\nfor example_data, example_labels in train_loader:\n    print(\"Input Size:\", example_data.size())  # Debugging size of input\n    example_image = example_data[0]  # Take the first image in the batch\n    example_image_numpy = example_image.permute(1, 2, 0).numpy()  # Convert (C, H, W) -> (H, W, C)\n    \n    # Plot the image\n    plt.imshow(example_image_numpy.squeeze(), cmap=\"gray\")  # Squeeze to remove empty channel\n    plt.title(f\"Label: {example_labels[0].item()}\")  # Get the label of the first image\n    plt.show()\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T07:10:30.907980Z","iopub.execute_input":"2024-12-31T07:10:30.908193Z","iopub.status.idle":"2024-12-31T07:10:31.155450Z","shell.execute_reply.started":"2024-12-31T07:10:30.908175Z","shell.execute_reply":"2024-12-31T07:10:31.154578Z"}},"outputs":[{"name":"stdout","text":"Input Size: torch.Size([64, 1, 28, 28])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgwUlEQVR4nO3de3BU9f3/8dcSYEFMFmLMTS4GUAEFtCCBETFChhAtI4hWrG2hRSwYHAQFG0dAWp0orcqgCI5VoiPe6AhW68TRQGDaBhCEIq3QhAkFhISLk13uIPn8/uDnfl1JgBM2eSfh+Zj5zGTP+bz3vHM85sXZc3Lic845AQBQz5pZNwAAuDgRQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAwAXavn27fD6f/vSnP0XtPYuKiuTz+VRUVBS19wQaGgIIF6X8/Hz5fD6tW7fOupU6sXTpUmVlZSk1NVV+v1/t27fXXXfdpc2bN1u3BoQ1t24AQPR99dVXateunSZPnqyEhASVl5fr9ddfV79+/VRcXKzevXtbtwgQQEBTNHPmzDOW3X///Wrfvr0WLFighQsXGnQFROIjOKAGJ06c0MyZM9WnTx8FAgG1adNGN998s1asWFFjzQsvvKBOnTqpdevWuuWWW6r9yGvLli266667FB8fr1atWqlv377661//es5+jhw5oi1btmj//v21+n4SExN1ySWXqLKyslb1QLQRQEANQqGQ/vznPysjI0PPPvusnnzySe3bt09ZWVnauHHjGfPffPNNzZs3Tzk5OcrNzdXmzZs1ePBgVVRUhOf8+9//Vv/+/fX111/rd7/7nZ577jm1adNGI0aM0NKlS8/az9q1a9W9e3e99NJL5/09VFZWat++ffrqq690//33KxQKaciQIeddD9QlPoIDatCuXTtt375dLVu2DC8bP368unXrphdffFGvvfZaxPzS0lKVlJToiiuukCQNGzZM6enpevbZZ/X8889LkiZPnqyOHTvqiy++kN/vlyQ9+OCDGjhwoB577DGNHDkyqt9D//79tXXrVknSpZdeqieeeELjxo2L6jaA2uIMCKhBTExMOHyqqqr07bff6rvvvlPfvn315ZdfnjF/xIgR4fCRpH79+ik9PV2ffPKJJOnbb7/V8uXL9bOf/UwHDx7U/v37tX//fh04cEBZWVkqKSnRN998U2M/GRkZcs7pySefPO/vYdGiRSooKNDLL7+s7t276+jRozp16tR51wN1iTMg4CzeeOMNPffcc9qyZYtOnjwZXp6WlnbG3KuuuuqMZVdffbXef/99SafPkJxzmjFjhmbMmFHt9vbu3RsRYhdqwIAB4a9Hjx6t7t27S1JUf2cJqC0CCKjBW2+9pbFjx2rEiBGaNm2aEhMTFRMTo7y8PG3bts3z+1VVVUmSHn30UWVlZVU7p2vXrhfU89m0a9dOgwcP1uLFiwkgNAgEEFCDv/zlL+rcubM++OAD+Xy+8PJZs2ZVO7+kpOSMZf/973915ZVXSpI6d+4sSWrRooUyMzOj3/B5OHr0qILBoMm2gR/jGhBQg5iYGEmScy68bM2aNSouLq52/rJlyyKu4axdu1Zr1qxRdna2pNO3QWdkZOiVV17Rnj17zqjft2/fWfvxchv23r17z1i2fft2FRYWqm/fvuesB+oDZ0C4qL3++usqKCg4Y/nkyZP105/+VB988IFGjhyp22+/XWVlZVq4cKF69OihQ4cOnVHTtWtXDRw4UBMnTtTx48c1d+5cXXbZZZo+fXp4zvz58zVw4ED17NlT48ePV+fOnVVRUaHi4mLt2rVL//rXv2rsde3atbr11ls1a9asc96I0LNnTw0ZMkTXX3+92rVrp5KSEr322ms6efKknnnmmfPfQUAdIoBwUVuwYEG1y8eOHauxY8eqvLxcr7zyij799FP16NFDb731lpYsWVLtQ0J/9atfqVmzZpo7d6727t2rfv366aWXXlJKSkp4To8ePbRu3TrNnj1b+fn5OnDggBITE3XDDTdU+/SC2po4caL+9re/qaCgQAcPHlRiYqKGDh2qxx9/XD179ozadoAL4XM//HwBAIB6wjUgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCiwf0eUFVVlXbv3q3Y2NiIx58AABoH55wOHjyo1NRUNWtW83lOgwug3bt3q0OHDtZtAAAu0M6dO9W+ffsa1ze4j+BiY2OtWwAARMG5fp7XWQDNnz9fV155pVq1aqX09HStXbv2vOr42A0AmoZz/TyvkwB67733NHXqVM2aNUtffvmlevfuraysrGqf0AsAuEi5OtCvXz+Xk5MTfn3q1CmXmprq8vLyzlkbDAadJAaDwWA08hEMBs/68z7qZ0AnTpzQ+vXrI/7gVrNmzZSZmVnt31E5fvy4QqFQxAAANH1RD6D9+/fr1KlTSkpKilielJSk8vLyM+bn5eUpEAiEB3fAAcDFwfwuuNzcXAWDwfDYuXOndUsAgHoQ9d8DSkhIUExMjCoqKiKWV1RUKDk5+Yz5fr9ffr8/2m0AABq4qJ8BtWzZUn369FFhYWF4WVVVlQoLCzVgwIBobw4A0EjVyZMQpk6dqjFjxqhv377q16+f5s6dq8OHD+vXv/51XWwOANAI1UkA3XPPPdq3b59mzpyp8vJyXX/99SooKDjjxgQAwMXL55xz1k38UCgUUiAQsG4DAHCBgsGg4uLialxvfhccAODiRAABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE82tGwAuRh06dPBcM336dM81o0eP9lwjSV988YXnmttuu61W28LFizMgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJngYKXCB7r//fs81ubm5nmvS0tI819RWbGxsvW0LFy/OgAAAJgggAICJqAfQk08+KZ/PFzG6desW7c0AABq5OrkGdO211+rzzz//v40051ITACBSnSRD8+bNlZycXBdvDQBoIurkGlBJSYlSU1PVuXNn3XfffdqxY0eNc48fP65QKBQxAABNX9QDKD09Xfn5+SooKNCCBQtUVlamm2++WQcPHqx2fl5engKBQHh06NAh2i0BABqgqAdQdna27r77bvXq1UtZWVn65JNPVFlZqffff7/a+bm5uQoGg+Gxc+fOaLcEAGiA6vzugLZt2+rqq69WaWlptev9fr/8fn9dtwEAaGDq/PeADh06pG3btiklJaWuNwUAaESiHkCPPvqoVq5cqe3bt+uf//ynRo4cqZiYGN17773R3hQAoBGL+kdwu3bt0r333qsDBw7o8ssv18CBA7V69Wpdfvnl0d4UAKAR8znnnHUTPxQKhRQIBKzbQCPXqlWrWtXNnj3bc83kyZM917Rs2dJzTX3atWuX55rBgwd7rqnp2jCahmAwqLi4uBrX8yw4AIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJur8D9IBFlq3bl2rumnTpkW5k+rt3bvXc82+ffs817Rt29ZzjSS1b9/ec01GRobnGh5GenHjDAgAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYMLnnHPWTfxQKBRSIBCwbgONXIsWLWpVN2rUKM81PXv29Fzz6quveq7Zvn2755px48Z5rpFq19+KFSs81wwZMsRzDRqPYDCouLi4GtdzBgQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBEc+sGgLpw8uTJWtW9++679VJTX5o3539xNFycAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBkwqBRuLqq6/2XPP000/XQSfVW758eb1tC00DZ0AAABMEEADAhOcAWrVqlYYPH67U1FT5fD4tW7YsYr1zTjNnzlRKSopat26tzMxMlZSURKtfAEAT4TmADh8+rN69e2v+/PnVrp8zZ47mzZunhQsXas2aNWrTpo2ysrJ07NixC24WANB0eL4JITs7W9nZ2dWuc85p7ty5euKJJ3THHXdIkt58800lJSVp2bJlGj169IV1CwBoMqJ6DaisrEzl5eXKzMwMLwsEAkpPT1dxcXG1NcePH1coFIoYAICmL6oBVF5eLklKSkqKWJ6UlBRe92N5eXkKBALh0aFDh2i2BABooMzvgsvNzVUwGAyPnTt3WrcEAKgHUQ2g5ORkSVJFRUXE8oqKivC6H/P7/YqLi4sYAICmL6oBlJaWpuTkZBUWFoaXhUIhrVmzRgMGDIjmpgAAjZznu+AOHTqk0tLS8OuysjJt3LhR8fHx6tixox5++GE99dRTuuqqq5SWlqYZM2YoNTVVI0aMiGbfAIBGznMArVu3Trfeemv49dSpUyVJY8aMUX5+vqZPn67Dhw/rgQceUGVlpQYOHKiCggK1atUqel0DABo9n3POWTfxQ6FQSIFAwLoNoE794he/8Fwzbdo0zzU9e/b0XCNJR48e9Vzzw3+Ynq+1a9d6rkHjEQwGz3pd3/wuOADAxYkAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYMLzn2MAGoOkpKRa1f32t7/1XHP33Xd7runRo4fnGp/P57mmtr777jvPNaFQqA46QVPGGRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATPIwUDV7//v0916xYsaJW2/L7/bWq8+qbb76pl5prr73Wc40kxcbGeq7JyMjwXLNlyxbPNWg6OAMCAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggoeRosErKSnxXPPuu+/Waltdu3b1XFNQUOC5Jj8/33NNbR5Gmpub67lGkp5++mnPNXfffbfnmoULF3quQdPBGRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATPIwUDd6BAwc81/zmN7+p1bZatGjhuebEiRO12lZ92Lt3b71ta9CgQZ5runXr5rlmy5YtnmvQMHEGBAAwQQABAEx4DqBVq1Zp+PDhSk1Nlc/n07JlyyLWjx07Vj6fL2IMGzYsWv0CAJoIzwF0+PBh9e7dW/Pnz69xzrBhw7Rnz57weOeddy6oSQBA0+P5JoTs7GxlZ2efdY7f71dycnKtmwIANH11cg2oqKhIiYmJuuaaazRx4sSz3sV0/PhxhUKhiAEAaPqiHkDDhg3Tm2++qcLCQj377LNauXKlsrOzderUqWrn5+XlKRAIhEeHDh2i3RIAoAGK+u8BjR49Ovx1z5491atXL3Xp0kVFRUUaMmTIGfNzc3M1derU8OtQKEQIAcBFoM5vw+7cubMSEhJUWlpa7Xq/36+4uLiIAQBo+uo8gHbt2qUDBw4oJSWlrjcFAGhEPH8Ed+jQoYizmbKyMm3cuFHx8fGKj4/X7NmzNWrUKCUnJ2vbtm2aPn26unbtqqysrKg2DgBo3DwH0Lp163TrrbeGX39//WbMmDFasGCBNm3apDfeeEOVlZVKTU3V0KFD9Yc//EF+vz96XQMAGj3PAZSRkSHnXI3rP/300wtqCIiGsx2jZ9OQHyza0MXExNRLDZoOngUHADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADAR9T/JDaBuJCcne6558MEH66CT6u3Zs8dzTWVlZfQbQaPBGRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATPIwUtdasmfd/v/zyl7/0XNO8uffDdMmSJZ5rJCkUCtWqzquYmBjPNRMmTPBcc8MNN3iuqa3XX3/dc80333xTB52gseAMCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkeRgrdddddtaqrzYNFhw8fXqtteTVx4sRa1fXt2zfKnVTv8ccf91wza9YszzXOOc81kpSXl+e5ZsGCBbXaFi5enAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAw4XO1fVphHQmFQgoEAtZtNFpdu3b1XLNhw4ZabatNmza1qqsPVVVVtaqbN2+e55revXt7rrnllls81zRr5v3fi3/4wx8810jS7NmzPdfUdp+j6QoGg4qLi6txPWdAAAATBBAAwISnAMrLy9ONN96o2NhYJSYmasSIEdq6dWvEnGPHjiknJ0eXXXaZLr30Uo0aNUoVFRVRbRoA0Ph5CqCVK1cqJydHq1ev1meffaaTJ09q6NChOnz4cHjOlClT9NFHH2nJkiVauXKldu/erTvvvDPqjQMAGjdPfxG1oKAg4nV+fr4SExO1fv16DRo0SMFgUK+99prefvttDR48WJK0aNEide/eXatXr1b//v2j1zkAoFG7oGtAwWBQkhQfHy9JWr9+vU6ePKnMzMzwnG7duqljx44qLi6u9j2OHz+uUCgUMQAATV+tA6iqqkoPP/ywbrrpJl133XWSpPLycrVs2VJt27aNmJuUlKTy8vJq3ycvL0+BQCA8OnToUNuWAACNSK0DKCcnR5s3b9a77757QQ3k5uYqGAyGx86dOy/o/QAAjYOna0DfmzRpkj7++GOtWrVK7du3Dy9PTk7WiRMnVFlZGXEWVFFRoeTk5Grfy+/3y+/316YNAEAj5ukMyDmnSZMmaenSpVq+fLnS0tIi1vfp00ctWrRQYWFheNnWrVu1Y8cODRgwIDodAwCaBE9nQDk5OXr77bf14YcfKjY2NnxdJxAIqHXr1goEAho3bpymTp2q+Ph4xcXF6aGHHtKAAQO4Aw4AEMFTAC1YsECSlJGREbF80aJFGjt2rCTphRdeULNmzTRq1CgdP35cWVlZevnll6PSLACg6eBhpE1MQkKC55qabpE/ly5duniuqc1NK4sXL/Zcs2TJEs81ktSqVata1XlVWVnpueaFF17wXPPUU095rpFOf9wOXCgeRgoAaJAIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACZ4GjY0ZcqUWtU999xzUe6kcXrjjTc81zz99NOea0pLSz3XAJZ4GjYAoEEigAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgorl1A7D36quv1qouNTXVc80jjzxSq215deLEiVrV3X333Z5rPvvsM881x44d81wDNDWcAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDhc8456yZ+KBQKKRAIWLcBALhAwWBQcXFxNa7nDAgAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACY8BVBeXp5uvPFGxcbGKjExUSNGjNDWrVsj5mRkZMjn80WMCRMmRLVpAEDj5ymAVq5cqZycHK1evVqfffaZTp48qaFDh+rw4cMR88aPH689e/aEx5w5c6LaNACg8WvuZXJBQUHE6/z8fCUmJmr9+vUaNGhQePkll1yi5OTk6HQIAGiSLugaUDAYlCTFx8dHLF+8eLESEhJ03XXXKTc3V0eOHKnxPY4fP65QKBQxAAAXAVdLp06dcrfffru76aabIpa/8sorrqCgwG3atMm99dZb7oorrnAjR46s8X1mzZrlJDEYDAajiY1gMHjWHKl1AE2YMMF16tTJ7dy586zzCgsLnSRXWlpa7fpjx465YDAYHjt37jTfaQwGg8G48HGuAPJ0Deh7kyZN0scff6xVq1apffv2Z52bnp4uSSotLVWXLl3OWO/3++X3+2vTBgCgEfMUQM45PfTQQ1q6dKmKioqUlpZ2zpqNGzdKklJSUmrVIACgafIUQDk5OXr77bf14YcfKjY2VuXl5ZKkQCCg1q1ba9u2bXr77bd122236bLLLtOmTZs0ZcoUDRo0SL169aqTbwAA0Eh5ue6jGj7nW7RokXPOuR07drhBgwa5+Ph45/f7XdeuXd20adPO+TngDwWDQfPPLRkMBoNx4eNcP/t9/z9YGoxQKKRAIGDdBgDgAgWDQcXFxdW4nmfBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMNLgAcs5ZtwAAiIJz/TxvcAF08OBB6xYAAFFwrp/nPtfATjmqqqq0e/duxcbGyufzRawLhULq0KGDdu7cqbi4OKMO7bEfTmM/nMZ+OI39cFpD2A/OOR08eFCpqalq1qzm85zm9djTeWnWrJnat29/1jlxcXEX9QH2PfbDaeyH09gPp7EfTrPeD4FA4JxzGtxHcACAiwMBBAAw0agCyO/3a9asWfL7/datmGI/nMZ+OI39cBr74bTGtB8a3E0IAICLQ6M6AwIANB0EEADABAEEADBBAAEATBBAAAATjSaA5s+fryuvvFKtWrVSenq61q5da91SvXvyySfl8/kiRrdu3azbqnOrVq3S8OHDlZqaKp/Pp2XLlkWsd85p5syZSklJUevWrZWZmamSkhKbZuvQufbD2LFjzzg+hg0bZtNsHcnLy9ONN96o2NhYJSYmasSIEdq6dWvEnGPHjiknJ0eXXXaZLr30Uo0aNUoVFRVGHdeN89kPGRkZZxwPEyZMMOq4eo0igN577z1NnTpVs2bN0pdffqnevXsrKytLe/futW6t3l177bXas2dPePz973+3bqnOHT58WL1799b8+fOrXT9nzhzNmzdPCxcu1Jo1a9SmTRtlZWXp2LFj9dxp3TrXfpCkYcOGRRwf77zzTj12WPdWrlypnJwcrV69Wp999plOnjypoUOH6vDhw+E5U6ZM0UcffaQlS5Zo5cqV2r17t+68807DrqPvfPaDJI0fPz7ieJgzZ45RxzVwjUC/fv1cTk5O+PWpU6dcamqqy8vLM+yq/s2aNcv17t3bug1TktzSpUvDr6uqqlxycrL74x//GF5WWVnp/H6/e+eddww6rB8/3g/OOTdmzBh3xx13mPRjZe/evU6SW7lypXPu9H/7Fi1auCVLloTnfP31106SKy4utmqzzv14Pzjn3C233OImT55s19R5aPBnQCdOnND69euVmZkZXtasWTNlZmaquLjYsDMbJSUlSk1NVefOnXXfffdpx44d1i2ZKisrU3l5ecTxEQgElJ6eflEeH0VFRUpMTNQ111yjiRMn6sCBA9Yt1algMChJio+PlyStX79eJ0+ejDgeunXrpo4dOzbp4+HH++F7ixcvVkJCgq677jrl5ubqyJEjFu3VqME9DfvH9u/fr1OnTikpKSlieVJSkrZs2WLUlY309HTl5+frmmuu0Z49ezR79mzdfPPN2rx5s2JjY63bM1FeXi5J1R4f36+7WAwbNkx33nmn0tLStG3bNj3++OPKzs5WcXGxYmJirNuLuqqqKj388MO66aabdN1110k6fTy0bNlSbdu2jZjblI+H6vaDJP385z9Xp06dlJqaqk2bNumxxx7T1q1b9cEHHxh2G6nBBxD+T3Z2dvjrXr16KT09XZ06ddL777+vcePGGXaGhmD06NHhr3v27KlevXqpS5cuKioq0pAhQww7qxs5OTnavHnzRXEd9Gxq2g8PPPBA+OuePXsqJSVFQ4YM0bZt29SlS5f6brNaDf4juISEBMXExJxxF0tFRYWSk5ONumoY2rZtq6uvvlqlpaXWrZj5/hjg+DhT586dlZCQ0CSPj0mTJunjjz/WihUrIv5+WHJysk6cOKHKysqI+U31eKhpP1QnPT1dkhrU8dDgA6hly5bq06ePCgsLw8uqqqpUWFioAQMGGHZm79ChQ9q2bZtSUlKsWzGTlpam5OTkiOMjFAppzZo1F/3xsWvXLh04cKBJHR/OOU2aNElLly7V8uXLlZaWFrG+T58+atGiRcTxsHXrVu3YsaNJHQ/n2g/V2bhxoyQ1rOPB+i6I8/Huu+86v9/v8vPz3X/+8x/3wAMPuLZt27ry8nLr1urVI4884oqKilxZWZn7xz/+4TIzM11CQoLbu3evdWt16uDBg27Dhg1uw4YNTpJ7/vnn3YYNG9z//vc/55xzzzzzjGvbtq378MMP3aZNm9wdd9zh0tLS3NGjR407j66z7YeDBw+6Rx991BUXF7uysjL3+eefu5/85CfuqquucseOHbNuPWomTpzoAoGAKyoqcnv27AmPI0eOhOdMmDDBdezY0S1fvtytW7fODRgwwA0YMMCw6+g7134oLS11v//97926detcWVmZ+/DDD13nzp3doEGDjDuP1CgCyDnnXnzxRdexY0fXsmVL169fP7d69WrrlurdPffc41JSUlzLli3dFVdc4e655x5XWlpq3VadW7FihZN0xhgzZoxz7vSt2DNmzHBJSUnO7/e7IUOGuK1bt9o2XQfOth+OHDnihg4d6i6//HLXokUL16lTJzd+/Pgm94+06r5/SW7RokXhOUePHnUPPviga9eunbvkkkvcyJEj3Z49e+yargPn2g87duxwgwYNcvHx8c7v97uuXbu6adOmuWAwaNv4j/D3gAAAJhr8NSAAQNNEAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABP/D57oaZQbfzJGAAAAAElFTkSuQmCC\n"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n        \n        # Dynamically determine the size of the flattened input\n        self.flatten_size = 128 * 3 * 3  # Correct size after pooling for MNIST images (28x28)\n        self.fc1 = nn.Linear(self.flatten_size, 128)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(128, 20)\n        self.fc3 = nn.Linear(20, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.pool(x)\n        x = self.conv2(x)\n        x = self.relu(x)\n        x = self.pool(x)\n        x = self.conv3(x)\n        x = self.relu(x)\n        x = self.pool(x)  # Final shape (batch_size, 128, 3, 3) for MNIST (28x28)\n\n        # Flatten the tensor\n        x = x.view(x.size(0), -1)  # Flatten dynamically using batch size\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.relu(x)\n        x = self.fc3(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T07:10:31.156450Z","iopub.execute_input":"2024-12-31T07:10:31.156778Z","iopub.status.idle":"2024-12-31T07:10:31.164191Z","shell.execute_reply.started":"2024-12-31T07:10:31.156745Z","shell.execute_reply":"2024-12-31T07:10:31.163352Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"model = SimpleCNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T07:10:31.164938Z","iopub.execute_input":"2024-12-31T07:10:31.165242Z","iopub.status.idle":"2024-12-31T07:10:31.183310Z","shell.execute_reply.started":"2024-12-31T07:10:31.165220Z","shell.execute_reply":"2024-12-31T07:10:31.182687Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"num_epochs = 100\n\nrunning_loss = 0.0\n\nfor epoch in range(num_epochs):\n    for i, data in enumerate(train_loader, 0):\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs.float())\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        if i % 100 == 99:\n            print(f\"[{epoch + 1}, {i +1}] Loss : {running_loss / 100: .3f}\")\n            running_loss = 0.0\n\n\nprint(\"Training Finished\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T07:37:37.516340Z","iopub.execute_input":"2024-12-31T07:37:37.516582Z"}},"outputs":[{"name":"stdout","text":"[1, 100] Loss :  0.001\n[1, 200] Loss :  0.001\n[1, 300] Loss :  0.001\n[1, 400] Loss :  0.001\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Test Dataset and DataLoader\ntest_dataset = CustomMNISTDataset(\n    \"/kaggle/input/digit-recognizer/test.csv\",\n    transform=data_transforms,\n    is_test=True\n)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n\n# Model evaluation and prediction\nmodel.eval()\npredictions = []\n\nwith torch.no_grad():\n    for data in test_loader:  # Test dataset only returns `data`\n        data = data.to(device)\n        outputs = model(data)\n        _, predicted = torch.max(outputs, 1)  # Get predicted labels\n        predictions.extend(predicted.cpu().tolist())\n\n# Creating the submission DataFrame\nsubmission = pd.DataFrame({\n    \"ImageId\": range(1, len(predictions) + 1),\n    \"Label\": predictions\n})\n\n# Save the predictions to a CSV file\nsubmission.to_csv('predictions_final.csv', index=False)\nprint(\"Submission file created: predictions_final.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-31T07:37:37.031707Z","iopub.status.idle":"2024-12-31T07:37:37.031987Z","shell.execute_reply":"2024-12-31T07:37:37.031866Z"}},"outputs":[],"execution_count":null}]}